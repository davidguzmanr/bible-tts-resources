{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb6ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio, display\n",
    "from mutagen.mp3 import MP3\n",
    "from mutagen.wave import WAVE\n",
    "\n",
    "from utils import download_audios, download_texts\n",
    "from utils import usx_parser\n",
    "from utils import audio_stats\n",
    "# from utils import force_align_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "290d5e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting audio files: 100%|██████████| 32289/32289 [01:10<00:00, 458.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL HOURS (all languages): 92.41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>testament_format</th>\n",
       "      <th>book</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>format</th>\n",
       "      <th>file_size_mb</th>\n",
       "      <th>duration_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21628</th>\n",
       "      <td>Alignment</td>\n",
       "      <td>Jeremiah</td>\n",
       "      <td>JER_051_Verse_021.wav</td>\n",
       "      <td>JER_051_Verse_021.wav</td>\n",
       "      <td>data/audios/Yoruba/Alignment/Jeremiah/JER_051_...</td>\n",
       "      <td>wav</td>\n",
       "      <td>47.91</td>\n",
       "      <td>523.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21630</th>\n",
       "      <td>Alignment</td>\n",
       "      <td>Jeremiah</td>\n",
       "      <td>JER_051_Verse_022.wav</td>\n",
       "      <td>JER_051_Verse_022.wav</td>\n",
       "      <td>data/audios/Yoruba/Alignment/Jeremiah/JER_051_...</td>\n",
       "      <td>wav</td>\n",
       "      <td>47.08</td>\n",
       "      <td>514.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>Alignment</td>\n",
       "      <td>Luke</td>\n",
       "      <td>LUK_023_Verse_016.wav</td>\n",
       "      <td>LUK_023_Verse_016.wav</td>\n",
       "      <td>data/audios/Yoruba/Alignment/Luke/LUK_023_Vers...</td>\n",
       "      <td>wav</td>\n",
       "      <td>33.22</td>\n",
       "      <td>362.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>Alignment</td>\n",
       "      <td>Luke</td>\n",
       "      <td>LUK_023_Verse_017.wav</td>\n",
       "      <td>LUK_023_Verse_017.wav</td>\n",
       "      <td>data/audios/Yoruba/Alignment/Luke/LUK_023_Vers...</td>\n",
       "      <td>wav</td>\n",
       "      <td>32.82</td>\n",
       "      <td>358.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>Alignment</td>\n",
       "      <td>John</td>\n",
       "      <td>JHN_018_Verse_013.wav</td>\n",
       "      <td>JHN_018_Verse_013.wav</td>\n",
       "      <td>data/audios/Yoruba/Alignment/John/JHN_018_Vers...</td>\n",
       "      <td>wav</td>\n",
       "      <td>29.24</td>\n",
       "      <td>319.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25223</th>\n",
       "      <td>Alignment</td>\n",
       "      <td>Leviticus</td>\n",
       "      <td>LEV_023_Verse_023.wav</td>\n",
       "      <td>LEV_023_Verse_023.wav</td>\n",
       "      <td>data/audios/Yoruba/Alignment/Leviticus/LEV_023...</td>\n",
       "      <td>wav</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>Alignment</td>\n",
       "      <td>Acts</td>\n",
       "      <td>ACT_018_Verse_004.wav</td>\n",
       "      <td>ACT_018_Verse_004.wav</td>\n",
       "      <td>data/audios/Yoruba/Alignment/Acts/ACT_018_Vers...</td>\n",
       "      <td>wav</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26935</th>\n",
       "      <td>Alignment</td>\n",
       "      <td>Numbers</td>\n",
       "      <td>NUM_026_Verse_052.wav</td>\n",
       "      <td>NUM_026_Verse_052.wav</td>\n",
       "      <td>data/audios/Yoruba/Alignment/Numbers/NUM_026_V...</td>\n",
       "      <td>wav</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Alignment</td>\n",
       "      <td>John</td>\n",
       "      <td>JHN_011_Verse_035.wav</td>\n",
       "      <td>JHN_011_Verse_035.wav</td>\n",
       "      <td>data/audios/Yoruba/Alignment/John/JHN_011_Vers...</td>\n",
       "      <td>wav</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22533</th>\n",
       "      <td>Alignment</td>\n",
       "      <td>Job</td>\n",
       "      <td>JOB_035_Verse_001.wav</td>\n",
       "      <td>JOB_035_Verse_001.wav</td>\n",
       "      <td>data/audios/Yoruba/Alignment/Job/JOB_035_Verse...</td>\n",
       "      <td>wav</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        language testament_format                   book  \\\n",
       "21628  Alignment         Jeremiah  JER_051_Verse_021.wav   \n",
       "21630  Alignment         Jeremiah  JER_051_Verse_022.wav   \n",
       "5157   Alignment             Luke  LUK_023_Verse_016.wav   \n",
       "5159   Alignment             Luke  LUK_023_Verse_017.wav   \n",
       "3794   Alignment             John  JHN_018_Verse_013.wav   \n",
       "...          ...              ...                    ...   \n",
       "25223  Alignment        Leviticus  LEV_023_Verse_023.wav   \n",
       "1962   Alignment             Acts  ACT_018_Verse_004.wav   \n",
       "26935  Alignment          Numbers  NUM_026_Verse_052.wav   \n",
       "3608   Alignment             John  JHN_011_Verse_035.wav   \n",
       "22533  Alignment              Job  JOB_035_Verse_001.wav   \n",
       "\n",
       "                   file_name  \\\n",
       "21628  JER_051_Verse_021.wav   \n",
       "21630  JER_051_Verse_022.wav   \n",
       "5157   LUK_023_Verse_016.wav   \n",
       "5159   LUK_023_Verse_017.wav   \n",
       "3794   JHN_018_Verse_013.wav   \n",
       "...                      ...   \n",
       "25223  LEV_023_Verse_023.wav   \n",
       "1962   ACT_018_Verse_004.wav   \n",
       "26935  NUM_026_Verse_052.wav   \n",
       "3608   JHN_011_Verse_035.wav   \n",
       "22533  JOB_035_Verse_001.wav   \n",
       "\n",
       "                                               file_path format  file_size_mb  \\\n",
       "21628  data/audios/Yoruba/Alignment/Jeremiah/JER_051_...    wav         47.91   \n",
       "21630  data/audios/Yoruba/Alignment/Jeremiah/JER_051_...    wav         47.08   \n",
       "5157   data/audios/Yoruba/Alignment/Luke/LUK_023_Vers...    wav         33.22   \n",
       "5159   data/audios/Yoruba/Alignment/Luke/LUK_023_Vers...    wav         32.82   \n",
       "3794   data/audios/Yoruba/Alignment/John/JHN_018_Vers...    wav         29.24   \n",
       "...                                                  ...    ...           ...   \n",
       "25223  data/audios/Yoruba/Alignment/Leviticus/LEV_023...    wav          0.18   \n",
       "1962   data/audios/Yoruba/Alignment/Acts/ACT_018_Vers...    wav          0.17   \n",
       "26935  data/audios/Yoruba/Alignment/Numbers/NUM_026_V...    wav          0.17   \n",
       "3608   data/audios/Yoruba/Alignment/John/JHN_011_Vers...    wav          0.16   \n",
       "22533  data/audios/Yoruba/Alignment/Job/JOB_035_Verse...    wav          0.15   \n",
       "\n",
       "       duration_seconds  \n",
       "21628            523.32  \n",
       "21630            514.27  \n",
       "5157             362.82  \n",
       "5159             358.47  \n",
       "3794             319.39  \n",
       "...                 ...  \n",
       "25223              1.91  \n",
       "1962               1.87  \n",
       "26935              1.83  \n",
       "3608               1.75  \n",
       "22533              1.65  \n",
       "\n",
       "[31100 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df = audio_stats.get_all_audio_files(audios_dir=\"data/audios/Yoruba\", alignment_filter=\"only\")\n",
    "\n",
    "total_hours_all_languages = audio_df[\"duration_seconds\"].sum() / 3600\n",
    "print(f\"TOTAL HOURS (all languages): {total_hours_all_languages:.2f}\")\n",
    "\n",
    "audio_df.sort_values(by=\"duration_seconds\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36924b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Book to testament mapping (constant, defined outside function)\n",
    "BOOK_TO_TESTAMENT = {\n",
    "    # Old Testament\n",
    "    \"Genesis\": \"Old Testament\",\n",
    "    \"Exodus\": \"Old Testament\",\n",
    "    \"Leviticus\": \"Old Testament\",\n",
    "    \"Numbers\": \"Old Testament\",\n",
    "    \"Deuteronomy\": \"Old Testament\",\n",
    "    \"Joshua\": \"Old Testament\",\n",
    "    \"Judges\": \"Old Testament\",\n",
    "    \"Ruth\": \"Old Testament\",\n",
    "    \"1 Samuel\": \"Old Testament\",\n",
    "    \"2 Samuel\": \"Old Testament\",\n",
    "    \"1 Kings\": \"Old Testament\",\n",
    "    \"2 Kings\": \"Old Testament\",\n",
    "    \"1 Chronicles\": \"Old Testament\",\n",
    "    \"2 Chronicles\": \"Old Testament\",\n",
    "    \"Ezra\": \"Old Testament\",\n",
    "    \"Nehemiah\": \"Old Testament\",\n",
    "    \"Esther\": \"Old Testament\",\n",
    "    \"Job\": \"Old Testament\",\n",
    "    \"Psalms\": \"Old Testament\",\n",
    "    \"Proverbs\": \"Old Testament\",\n",
    "    \"Ecclesiastes\": \"Old Testament\",\n",
    "    \"Song of Songs\": \"Old Testament\",\n",
    "    \"Isaiah\": \"Old Testament\",\n",
    "    \"Jeremiah\": \"Old Testament\",\n",
    "    \"Lamentations\": \"Old Testament\",\n",
    "    \"Ezekiel\": \"Old Testament\",\n",
    "    \"Daniel\": \"Old Testament\",\n",
    "    \"Hosea\": \"Old Testament\",\n",
    "    \"Joel\": \"Old Testament\",\n",
    "    \"Amos\": \"Old Testament\",\n",
    "    \"Obadiah\": \"Old Testament\",\n",
    "    \"Jonah\": \"Old Testament\",\n",
    "    \"Micah\": \"Old Testament\",\n",
    "    \"Nahum\": \"Old Testament\",\n",
    "    \"Habakkuk\": \"Old Testament\",\n",
    "    \"Zephaniah\": \"Old Testament\",\n",
    "    \"Haggai\": \"Old Testament\",\n",
    "    \"Zechariah\": \"Old Testament\",\n",
    "    \"Malachi\": \"Old Testament\",\n",
    "    # New Testament\n",
    "    \"Matthew\": \"New Testament\",\n",
    "    \"Mark\": \"New Testament\",\n",
    "    \"Luke\": \"New Testament\",\n",
    "    \"John\": \"New Testament\",\n",
    "    \"Acts\": \"New Testament\",\n",
    "    \"Romans\": \"New Testament\",\n",
    "    \"1 Corinthians\": \"New Testament\",\n",
    "    \"2 Corinthians\": \"New Testament\",\n",
    "    \"Galatians\": \"New Testament\",\n",
    "    \"Ephesians\": \"New Testament\",\n",
    "    \"Philippians\": \"New Testament\",\n",
    "    \"Colossians\": \"New Testament\",\n",
    "    \"1 Thessalonians\": \"New Testament\",\n",
    "    \"2 Thessalonians\": \"New Testament\",\n",
    "    \"1 Timothy\": \"New Testament\",\n",
    "    \"2 Timothy\": \"New Testament\",\n",
    "    \"Titus\": \"New Testament\",\n",
    "    \"Philemon\": \"New Testament\",\n",
    "    \"Hebrews\": \"New Testament\",\n",
    "    \"James\": \"New Testament\",\n",
    "    \"1 Peter\": \"New Testament\",\n",
    "    \"2 Peter\": \"New Testament\",\n",
    "    \"1 John\": \"New Testament\",\n",
    "    \"2 John\": \"New Testament\",\n",
    "    \"3 John\": \"New Testament\",\n",
    "    \"Jude\": \"New Testament\",\n",
    "    \"Revelation\": \"New Testament\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_alignment_dataframe(language: str, base_dir: str = \"data/audios\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load alignment data for a given language and return a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        language: The language name (e.g., \"Yoruba\")\n",
    "        base_dir: Base directory for audio files (default: \"data/audios\")\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: audio_file, text_file, text, book, chapter, \n",
    "                               verse, testament, duration_seconds\n",
    "    \"\"\"\n",
    "    alignment_dir = os.path.join(base_dir, language, \"Alignment\")\n",
    "    \n",
    "    # Collect all audio files recursively (.wav and .mp3)\n",
    "    audio_files = []\n",
    "    for root, dirs, files in os.walk(alignment_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.wav', '.mp3')):\n",
    "                audio_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # Each audio file has a corresponding .txt file with the same name\n",
    "    text_files = [os.path.splitext(x)[0] + \".txt\" for x in audio_files]\n",
    "    \n",
    "    # Build initial dataframe with file paths\n",
    "    df = pd.DataFrame({\n",
    "        \"audio_file\": audio_files,\n",
    "        \"text_file\": text_files,\n",
    "    })\n",
    "    \n",
    "    # Helper to safely read text file contents\n",
    "    def read_text_file(file_path):\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                return f.read()\n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    # Read transcript text from each text file\n",
    "    df[\"text\"] = df[\"text_file\"].apply(read_text_file)\n",
    "    \n",
    "    # Extract metadata from file path structure:\n",
    "    # Format: .../Alignment/{Book}/{BOOK_CHAPTER_Verse_VERSE}.txt\n",
    "    df[\"book\"] = df[\"text_file\"].apply(lambda x: x.split(\"/\")[-2])\n",
    "    df[\"chapter\"] = df[\"text_file\"].apply(lambda x: x.replace(\".txt\", \"\").split(\"/\")[-1].split(\"_\")[1])\n",
    "    df[\"verse\"] = df[\"text_file\"].apply(lambda x: x.replace(\".txt\", \"\").split(\"/\")[-1].split(\"_\")[-1])\n",
    "    \n",
    "    # Map book name to testament (Old/New)\n",
    "    df[\"testament\"] = df[\"book\"].map(BOOK_TO_TESTAMENT)\n",
    "    \n",
    "    # Get audio duration in seconds\n",
    "    df[\"duration_seconds\"] = df[\"audio_file\"].apply(audio_stats.get_audio_duration)\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df[[\"audio_file\", \"text\", \"testament\", \"book\", \"chapter\", \"verse\", \"duration_seconds\"]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a67f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>text</th>\n",
       "      <th>testament</th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>duration_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/audios/Yoruba/Alignment/1 Corinthians/1CO...</td>\n",
       "      <td>Paulu, ẹni ti a pé láti jẹ́ aposteli Kristi Je...</td>\n",
       "      <td>New Testament</td>\n",
       "      <td>1 Corinthians</td>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>8.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/audios/Yoruba/Alignment/1 Corinthians/1CO...</td>\n",
       "      <td>Sí ìjọ ènìyàn Ọlọ́run ni Kọrinti, sí àwọn ti a...</td>\n",
       "      <td>New Testament</td>\n",
       "      <td>1 Corinthians</td>\n",
       "      <td>001</td>\n",
       "      <td>002</td>\n",
       "      <td>17.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/audios/Yoruba/Alignment/1 Corinthians/1CO...</td>\n",
       "      <td>Oore-ọ̀fẹ́ àti àlàáfíà fún yín láti ọ̀dọ̀ Ọlọ́...</td>\n",
       "      <td>New Testament</td>\n",
       "      <td>1 Corinthians</td>\n",
       "      <td>001</td>\n",
       "      <td>003</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/audios/Yoruba/Alignment/1 Corinthians/1CO...</td>\n",
       "      <td>Nígbà gbogbo ni mo ń dúpẹ́ lọ́wọ́ Ọlọ́run fún ...</td>\n",
       "      <td>New Testament</td>\n",
       "      <td>1 Corinthians</td>\n",
       "      <td>001</td>\n",
       "      <td>004</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/audios/Yoruba/Alignment/1 Corinthians/1CO...</td>\n",
       "      <td>Nítorí nínú rẹ̀ ni a ti sọ yín di ọlọ́rọ̀ nínú...</td>\n",
       "      <td>New Testament</td>\n",
       "      <td>1 Corinthians</td>\n",
       "      <td>001</td>\n",
       "      <td>005</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          audio_file  \\\n",
       "0  data/audios/Yoruba/Alignment/1 Corinthians/1CO...   \n",
       "1  data/audios/Yoruba/Alignment/1 Corinthians/1CO...   \n",
       "2  data/audios/Yoruba/Alignment/1 Corinthians/1CO...   \n",
       "3  data/audios/Yoruba/Alignment/1 Corinthians/1CO...   \n",
       "4  data/audios/Yoruba/Alignment/1 Corinthians/1CO...   \n",
       "\n",
       "                                                text      testament  \\\n",
       "0  Paulu, ẹni ti a pé láti jẹ́ aposteli Kristi Je...  New Testament   \n",
       "1  Sí ìjọ ènìyàn Ọlọ́run ni Kọrinti, sí àwọn ti a...  New Testament   \n",
       "2  Oore-ọ̀fẹ́ àti àlàáfíà fún yín láti ọ̀dọ̀ Ọlọ́...  New Testament   \n",
       "3  Nígbà gbogbo ni mo ń dúpẹ́ lọ́wọ́ Ọlọ́run fún ...  New Testament   \n",
       "4  Nítorí nínú rẹ̀ ni a ti sọ yín di ọlọ́rọ̀ nínú...  New Testament   \n",
       "\n",
       "            book chapter verse  duration_seconds  \n",
       "0  1 Corinthians     001   001              8.93  \n",
       "1  1 Corinthians     001   002             17.72  \n",
       "2  1 Corinthians     001   003              8.90  \n",
       "3  1 Corinthians     001   004              6.91  \n",
       "4  1 Corinthians     001   005              7.15  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language = \"Yoruba\"\n",
    "base_dir = \"data/audios\"\n",
    "\n",
    "alignment_df = get_alignment_dataframe(language, base_dir)\n",
    "alignment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f461587",
   "metadata": {},
   "source": [
    "## Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a17856f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_df_renamed = alignment_df.rename(columns={\"audio_file\": \"wav_filename\", \"text\": \"transcript\"})\n",
    "alignment_df_renamed.to_csv(\"data-checker/files/Yoruba.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5edb7ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>transcript</th>\n",
       "      <th>testament</th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>duration_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/audios/Yoruba/Alignment/1 Corinthians/1CO...</td>\n",
       "      <td>Paulu, ẹni ti a pé láti jẹ́ aposteli Kristi Je...</td>\n",
       "      <td>New Testament</td>\n",
       "      <td>1 Corinthians</td>\n",
       "      <td>001</td>\n",
       "      <td>001</td>\n",
       "      <td>8.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/audios/Yoruba/Alignment/1 Corinthians/1CO...</td>\n",
       "      <td>Sí ìjọ ènìyàn Ọlọ́run ni Kọrinti, sí àwọn ti a...</td>\n",
       "      <td>New Testament</td>\n",
       "      <td>1 Corinthians</td>\n",
       "      <td>001</td>\n",
       "      <td>002</td>\n",
       "      <td>17.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/audios/Yoruba/Alignment/1 Corinthians/1CO...</td>\n",
       "      <td>Oore-ọ̀fẹ́ àti àlàáfíà fún yín láti ọ̀dọ̀ Ọlọ́...</td>\n",
       "      <td>New Testament</td>\n",
       "      <td>1 Corinthians</td>\n",
       "      <td>001</td>\n",
       "      <td>003</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/audios/Yoruba/Alignment/1 Corinthians/1CO...</td>\n",
       "      <td>Nígbà gbogbo ni mo ń dúpẹ́ lọ́wọ́ Ọlọ́run fún ...</td>\n",
       "      <td>New Testament</td>\n",
       "      <td>1 Corinthians</td>\n",
       "      <td>001</td>\n",
       "      <td>004</td>\n",
       "      <td>6.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/audios/Yoruba/Alignment/1 Corinthians/1CO...</td>\n",
       "      <td>Nítorí nínú rẹ̀ ni a ti sọ yín di ọlọ́rọ̀ nínú...</td>\n",
       "      <td>New Testament</td>\n",
       "      <td>1 Corinthians</td>\n",
       "      <td>001</td>\n",
       "      <td>005</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31095</th>\n",
       "      <td>data/audios/Yoruba/Alignment/Zephaniah/ZEP_003...</td>\n",
       "      <td>Ní ọjọ́ náà, wọn yóò sọ fún Jerusalẹmu pé, “Má...</td>\n",
       "      <td>Old Testament</td>\n",
       "      <td>Zephaniah</td>\n",
       "      <td>003</td>\n",
       "      <td>016</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31096</th>\n",
       "      <td>data/audios/Yoruba/Alignment/Zephaniah/ZEP_003...</td>\n",
       "      <td>Olúwa Ọlọ́run rẹ wà pẹ̀lú rẹ, Ó ní agbára láti...</td>\n",
       "      <td>Old Testament</td>\n",
       "      <td>Zephaniah</td>\n",
       "      <td>003</td>\n",
       "      <td>017</td>\n",
       "      <td>14.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31097</th>\n",
       "      <td>data/audios/Yoruba/Alignment/Zephaniah/ZEP_003...</td>\n",
       "      <td>“Èmi ó kó àwọn tí ó ń banújẹ́ fún àjọ̀dún tí a...</td>\n",
       "      <td>Old Testament</td>\n",
       "      <td>Zephaniah</td>\n",
       "      <td>003</td>\n",
       "      <td>018</td>\n",
       "      <td>8.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31098</th>\n",
       "      <td>data/audios/Yoruba/Alignment/Zephaniah/ZEP_003...</td>\n",
       "      <td>Ní àkókò náà ni èmi yóò dojúkọ àwọn tí ń ni yí...</td>\n",
       "      <td>Old Testament</td>\n",
       "      <td>Zephaniah</td>\n",
       "      <td>003</td>\n",
       "      <td>019</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31099</th>\n",
       "      <td>data/audios/Yoruba/Alignment/Zephaniah/ZEP_003...</td>\n",
       "      <td>Ní àkókò náà ni èmi yóò ṣà yín jọ; nígbà náà n...</td>\n",
       "      <td>Old Testament</td>\n",
       "      <td>Zephaniah</td>\n",
       "      <td>003</td>\n",
       "      <td>020</td>\n",
       "      <td>19.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            wav_filename  \\\n",
       "0      data/audios/Yoruba/Alignment/1 Corinthians/1CO...   \n",
       "1      data/audios/Yoruba/Alignment/1 Corinthians/1CO...   \n",
       "2      data/audios/Yoruba/Alignment/1 Corinthians/1CO...   \n",
       "3      data/audios/Yoruba/Alignment/1 Corinthians/1CO...   \n",
       "4      data/audios/Yoruba/Alignment/1 Corinthians/1CO...   \n",
       "...                                                  ...   \n",
       "31095  data/audios/Yoruba/Alignment/Zephaniah/ZEP_003...   \n",
       "31096  data/audios/Yoruba/Alignment/Zephaniah/ZEP_003...   \n",
       "31097  data/audios/Yoruba/Alignment/Zephaniah/ZEP_003...   \n",
       "31098  data/audios/Yoruba/Alignment/Zephaniah/ZEP_003...   \n",
       "31099  data/audios/Yoruba/Alignment/Zephaniah/ZEP_003...   \n",
       "\n",
       "                                              transcript      testament  \\\n",
       "0      Paulu, ẹni ti a pé láti jẹ́ aposteli Kristi Je...  New Testament   \n",
       "1      Sí ìjọ ènìyàn Ọlọ́run ni Kọrinti, sí àwọn ti a...  New Testament   \n",
       "2      Oore-ọ̀fẹ́ àti àlàáfíà fún yín láti ọ̀dọ̀ Ọlọ́...  New Testament   \n",
       "3      Nígbà gbogbo ni mo ń dúpẹ́ lọ́wọ́ Ọlọ́run fún ...  New Testament   \n",
       "4      Nítorí nínú rẹ̀ ni a ti sọ yín di ọlọ́rọ̀ nínú...  New Testament   \n",
       "...                                                  ...            ...   \n",
       "31095  Ní ọjọ́ náà, wọn yóò sọ fún Jerusalẹmu pé, “Má...  Old Testament   \n",
       "31096  Olúwa Ọlọ́run rẹ wà pẹ̀lú rẹ, Ó ní agbára láti...  Old Testament   \n",
       "31097  “Èmi ó kó àwọn tí ó ń banújẹ́ fún àjọ̀dún tí a...  Old Testament   \n",
       "31098  Ní àkókò náà ni èmi yóò dojúkọ àwọn tí ń ni yí...  Old Testament   \n",
       "31099  Ní àkókò náà ni èmi yóò ṣà yín jọ; nígbà náà n...  Old Testament   \n",
       "\n",
       "                book chapter verse  duration_seconds  \n",
       "0      1 Corinthians     001   001              8.93  \n",
       "1      1 Corinthians     001   002             17.72  \n",
       "2      1 Corinthians     001   003              8.90  \n",
       "3      1 Corinthians     001   004              6.91  \n",
       "4      1 Corinthians     001   005              7.15  \n",
       "...              ...     ...   ...               ...  \n",
       "31095      Zephaniah     003   016              8.22  \n",
       "31096      Zephaniah     003   017             14.61  \n",
       "31097      Zephaniah     003   018              8.69  \n",
       "31098      Zephaniah     003   019             14.33  \n",
       "31099      Zephaniah     003   020             19.20  \n",
       "\n",
       "[31100 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_df_renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a606644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29933, 16)\n"
     ]
    }
   ],
   "source": [
    "best = pd.read_csv(\"data-checker/files/Yoruba.BEST\")\n",
    "print(best.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1016f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "python data-checker/data_checks.py data-checker/files/Yoruba.csv 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cb94cd",
   "metadata": {},
   "source": [
    "## Upload to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7df055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/g/guzmand/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Audio\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "def upload_alignment_to_hf(\n",
    "    alignment_df: pd.DataFrame,\n",
    "    language: str,\n",
    "    repo_id: str,\n",
    "    private: bool = False,\n",
    "    max_shard_size: str = \"200MB\",\n",
    "    max_retries: int = 3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Upload alignment data as a TTS dataset to Hugging Face Hub.\n",
    "    \n",
    "    Args:\n",
    "        alignment_df: DataFrame with audio_file, text, and metadata columns\n",
    "        language: Language name to use as the split/config name\n",
    "        repo_id: Hugging Face repository ID (e.g., \"username/bible-tts\")\n",
    "        private: Whether the dataset should be private\n",
    "        max_shard_size: Maximum shard size for upload (smaller = more reliable)\n",
    "        max_retries: Number of retries on timeout errors\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df = alignment_df.copy()\n",
    "    \n",
    "    # Rename audio_file to audio for HF convention\n",
    "    df = df.rename(columns={\"audio_file\": \"audio\"})\n",
    "    \n",
    "    # Create HF Dataset\n",
    "    dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "    \n",
    "    # Cast the audio column to Audio feature (this handles loading the actual audio files)\n",
    "    dataset = dataset.cast_column(\"audio\", Audio())\n",
    "    \n",
    "    # Push to hub with retry logic for timeout errors\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            dataset.push_to_hub(\n",
    "                repo_id=repo_id,\n",
    "                config_name=language,  # Use language as the config name\n",
    "                split=\"train\",  # HF requires a split name, but you can ignore it when loading\n",
    "                private=private,\n",
    "                max_shard_size=max_shard_size,  # Smaller shards for more reliable uploads\n",
    "            )\n",
    "            print(f\"✓ Uploaded {len(dataset)} samples for '{language}' to {repo_id}\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            if \"timeout\" in str(e).lower() or \"ReadTimeout\" in str(type(e).__name__):\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = (attempt + 1) * 30  # 30s, 60s, 90s\n",
    "                    print(f\"⚠ Timeout on attempt {attempt + 1}/{max_retries}. Retrying in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"✗ Failed after {max_retries} attempts. The data may have uploaded - check the repo.\")\n",
    "                    raise\n",
    "            else:\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764029f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading languages:   0%|          | 0/38 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing 'Apali' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 232.01 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00,  7.62ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  125MB /  125MB, 56.8MB/s  \n",
      "New Data Upload: 100%|██████████|  125MB /  125MB, 56.8MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:05<00:00,  5.72s/ shards]\n",
      "Uploading languages:   3%|▎         | 1/38 [00:35<21:40, 35.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Apali' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Apali'\n",
      "\n",
      "--- Processing 'Arabic Standard' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 478.27 examples/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 16.49ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 37.5MB / 37.5MB, 37.4MB/s  \n",
      "New Data Upload: 100%|██████████| 37.5MB / 37.5MB, 37.4MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.02s/ shards]\n",
      "Uploading languages:   5%|▌         | 2/38 [01:46<33:53, 56.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Arabic Standard' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Arabic Standard'\n",
      "\n",
      "--- Processing 'Assamese' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 259.14 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  4.75ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 73.9MB / 73.9MB, 41.0MB/s  \n",
      "New Data Upload: 100%|██████████| 73.9MB / 73.9MB, 41.0MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:05<00:00,  5.26s/ shards]\n",
      "Uploading languages:   8%|▊         | 3/38 [03:11<40:26, 69.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Assamese' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Assamese'\n",
      "\n",
      "--- Processing 'Bengali' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 228.06 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00,  8.62ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 88.2MB / 88.2MB, 49.0MB/s  \n",
      "New Data Upload: 100%|██████████| 88.2MB / 88.2MB, 49.0MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:07<00:00,  7.77s/ shards]\n",
      "Uploading languages:  11%|█         | 4/38 [04:50<45:57, 81.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Bengali' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Bengali'\n",
      "\n",
      "--- Processing 'Central Kurdish' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 257.82 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 12.12ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 96.4MB / 96.4MB, 53.6MB/s  \n",
      "New Data Upload: 100%|██████████| 96.4MB / 96.4MB, 53.6MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:06<00:00,  6.08s/ shards]\n",
      "Uploading languages:  13%|█▎        | 5/38 [06:10<44:19, 80.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Central Kurdish' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Central Kurdish'\n",
      "\n",
      "--- Processing 'Chhattisgarhi' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 256.93 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 11.15ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 96.2MB / 96.2MB, 53.4MB/s  \n",
      "New Data Upload: 100%|██████████| 96.2MB / 96.2MB, 53.4MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:05<00:00,  5.99s/ shards]\n",
      "Uploading languages:  16%|█▌        | 6/38 [07:34<43:37, 81.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Chhattisgarhi' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Chhattisgarhi'\n",
      "\n",
      "--- Processing 'Chichewa' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 370.13 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  5.34ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 55.0MB / 55.0MB, 39.3MB/s  \n",
      "New Data Upload: 100%|██████████| 55.0MB / 55.0MB, 39.3MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.21s/ shards]\n",
      "Uploading languages:  18%|█▊        | 7/38 [08:39<39:28, 76.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Chichewa' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Chichewa'\n",
      "\n",
      "--- Processing 'Dawro' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 307.75 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  8.93ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 45.9MB / 45.9MB, 38.2MB/s  \n",
      "New Data Upload: 100%|██████████| 45.9MB / 45.9MB, 38.2MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.74s/ shards]\n",
      "Uploading languages:  21%|██        | 8/38 [09:42<36:07, 72.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Dawro' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Dawro'\n",
      "\n",
      "--- Processing 'Dholuo' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 273.02 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  4.78ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 75.7MB / 75.7MB, 42.0MB/s  \n",
      "New Data Upload: 100%|██████████| 75.7MB / 75.7MB, 42.0MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.90s/ shards]\n",
      "Uploading languages:  24%|██▎       | 9/38 [10:54<34:50, 72.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Dholuo' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Dholuo'\n",
      "\n",
      "--- Processing 'Ewe' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 225.73 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 11.51ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 91.4MB / 91.4MB, 50.8MB/s  \n",
      "New Data Upload: 100%|██████████| 91.4MB / 91.4MB, 50.8MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.36s/ shards]\n",
      "Uploading languages:  26%|██▋       | 10/38 [12:10<34:09, 73.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Ewe' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Ewe'\n",
      "\n",
      "--- Processing 'Gamo' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 386.01 examples/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 13.35ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 37.6MB / 37.6MB, 31.4MB/s  \n",
      "New Data Upload: 100%|██████████| 37.6MB / 37.6MB, 31.4MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.56s/ shards]\n",
      "Uploading languages:  29%|██▉       | 11/38 [13:15<31:51, 70.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Gamo' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Gamo'\n",
      "\n",
      "--- Processing 'Gofa' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 158.83 examples/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 16.58ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 32.4MB / 32.4MB, 31.9MB/s  \n",
      "New Data Upload: 100%|██████████| 32.4MB / 32.4MB, 31.9MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.63s/ shards]\n",
      "Uploading languages:  32%|███▏      | 12/38 [14:19<29:49, 68.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Gofa' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Gofa'\n",
      "\n",
      "--- Processing 'Gujarati' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 245.21 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.08ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 82.0MB / 82.0MB, 41.0MB/s  \n",
      "New Data Upload: 100%|██████████| 82.0MB / 82.0MB, 41.0MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.66s/ shards]\n",
      "Uploading languages:  34%|███▍      | 13/38 [15:33<29:20, 70.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Gujarati' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Gujarati'\n",
      "\n",
      "--- Processing 'Haitian Creole' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 388.31 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.87ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 49.8MB / 49.8MB, 35.5MB/s  \n",
      "New Data Upload: 100%|██████████| 49.8MB / 49.8MB, 35.5MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.93s/ shards]\n",
      "Uploading languages:  37%|███▋      | 14/38 [16:41<27:46, 69.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Haitian Creole' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Haitian Creole'\n",
      "\n",
      "--- Processing 'Hausa' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 317.98 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  4.91ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 64.5MB / 64.5MB, 40.3MB/s  \n",
      "New Data Upload: 100%|██████████| 64.5MB / 64.5MB, 40.3MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.92s/ shards]\n",
      "Uploading languages:  39%|███▉      | 15/38 [17:16<22:39, 59.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Hausa' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Hausa'\n",
      "\n",
      "--- Processing 'Hiligaynon' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 190.84 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00,  9.72ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  107MB /  107MB, 59.5MB/s  \n",
      "New Data Upload: 100%|██████████|  107MB /  107MB, 59.5MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.89s/ shards]\n",
      "Uploading languages:  42%|████▏     | 16/38 [19:12<27:58, 76.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Hiligaynon' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Hiligaynon'\n",
      "\n",
      "--- Processing 'Hindi' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 234.69 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00,  6.79ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  100MB /  100MB, 55.5MB/s  \n",
      "New Data Upload: 100%|██████████|  100MB /  100MB, 55.5MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.55s/ shards]\n",
      "Uploading languages:  45%|████▍     | 17/38 [20:31<26:57, 77.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Hindi' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Hindi'\n",
      "\n",
      "--- Processing 'Igbo' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 194.00 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00,  5.73ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  106MB /  106MB, 48.2MB/s  \n",
      "New Data Upload: 100%|██████████|  106MB /  106MB, 48.2MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:05<00:00,  5.21s/ shards]\n",
      "Uploading languages:  47%|████▋     | 18/38 [21:52<26:07, 78.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Igbo' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Igbo'\n",
      "\n",
      "--- Processing 'Kannada' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 222.26 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00,  7.84ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 97.7MB / 97.7MB, 54.3MB/s  \n",
      "New Data Upload: 100%|██████████| 97.7MB / 97.7MB, 54.3MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.49s/ shards]\n",
      "Uploading languages:  50%|█████     | 19/38 [23:12<24:58, 78.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Kannada' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Kannada'\n",
      "\n",
      "--- Processing 'Kikuyu' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 538.17 examples/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 10.97ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 40.7MB / 40.7MB, 33.9MB/s  \n",
      "New Data Upload: 100%|██████████| 40.7MB / 40.7MB, 33.9MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.56s/ shards]\n",
      "Uploading languages:  53%|█████▎    | 20/38 [24:16<22:16, 74.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Kikuyu' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Kikuyu'\n",
      "\n",
      "--- Processing 'Lingala' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 166.66 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00,  6.69ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  115MB /  115MB, 52.2MB/s  \n",
      "New Data Upload: 100%|██████████|  115MB /  115MB, 52.2MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:05<00:00,  5.41s/ shards]\n",
      "Uploading languages:  55%|█████▌    | 21/38 [25:33<21:17, 75.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Lingala' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Lingala'\n",
      "\n",
      "--- Processing 'Luganda' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 422.70 examples/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 15.55ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 40.4MB / 40.4MB, 28.9MB/s  \n",
      "New Data Upload: 100%|██████████| 40.4MB / 40.4MB, 28.9MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.75s/ shards]\n",
      "Uploading languages:  58%|█████▊    | 22/38 [26:41<19:26, 72.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Luganda' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Luganda'\n",
      "\n",
      "--- Processing 'Malayalam' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 244.77 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.73ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 72.5MB / 72.5MB, 24.2MB/s  \n",
      "New Data Upload: 100%|██████████| 72.5MB / 72.5MB, 24.2MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:05<00:00,  5.11s/ shards]\n",
      "Uploading languages:  61%|██████    | 23/38 [27:53<18:12, 72.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Malayalam' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Malayalam'\n",
      "\n",
      "--- Processing 'Marathi' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 287.23 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.04ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 72.9MB / 72.9MB, 40.5MB/s  \n",
      "New Data Upload: 100%|██████████| 72.9MB / 72.9MB, 40.5MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.10s/ shards]\n",
      "Uploading languages:  63%|██████▎   | 24/38 [29:08<17:06, 73.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Marathi' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Marathi'\n",
      "\n",
      "--- Processing 'Ndebele' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 245.40 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 11.65ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 87.2MB / 87.2MB, 43.6MB/s  \n",
      "New Data Upload: 100%|██████████| 87.2MB / 87.2MB, 43.6MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.42s/ shards]\n",
      "Uploading languages:  66%|██████▌   | 25/38 [30:39<17:02, 78.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Ndebele' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Ndebele'\n",
      "\n",
      "--- Processing 'Oromo' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 239.76 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 11.04ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 84.8MB / 84.8MB, 47.1MB/s  \n",
      "New Data Upload: 100%|██████████| 84.8MB / 84.8MB, 47.1MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.19s/ shards]\n",
      "Uploading languages:  68%|██████▊   | 26/38 [31:55<15:32, 77.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Oromo' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Oromo'\n",
      "\n",
      "--- Processing 'Punjabi' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 234.73 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  4.40ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 85.1MB / 85.1MB, 42.5MB/s  \n",
      "New Data Upload: 100%|██████████| 85.1MB / 85.1MB, 42.5MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.62s/ shards]\n",
      "Uploading languages:  71%|███████   | 27/38 [33:11<14:10, 77.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded 100 samples for 'Punjabi' to davidguzmanr/bible-tts-resources\n",
      "✓ Finished uploading 'Punjabi'\n",
      "\n",
      "--- Processing 'Shona' ---\n"
     ]
    }
   ],
   "source": [
    "LANGUAGES = [\n",
    "    'Apali',\n",
    "    'Arabic Standard',\n",
    "    'Assamese',\n",
    "    'Bengali',\n",
    "    'Central Kurdish',\n",
    "    'Chhattisgarhi',\n",
    "    'Chichewa',\n",
    "    'Dawro',\n",
    "    'Dholuo',\n",
    "    'Ewe',\n",
    "    'Gamo',\n",
    "    'Gofa',\n",
    "    'Gujarati',\n",
    "    'Haitian Creole',\n",
    "    # 'Haryanvi',\n",
    "    'Hausa',\n",
    "    'Hiligaynon',\n",
    "    'Hindi',\n",
    "    'Igbo',\n",
    "    'Kannada',\n",
    "    'Kikuyu',\n",
    "    'Lingala',\n",
    "    'Luganda',\n",
    "    'Malayalam',\n",
    "    'Marathi',\n",
    "    'Ndebele',\n",
    "    'Oromo',\n",
    "    'Punjabi',\n",
    "    'Shona',\n",
    "    'Swahili',\n",
    "    'Tamil',\n",
    "    'Telugu',\n",
    "    # 'Toma',\n",
    "    'Turkish',\n",
    "    'Twi (Akuapem)',\n",
    "    'Twi (Asante)',\n",
    "    'Ukrainian',\n",
    "    'Urdu',\n",
    "    'Vietnamese',\n",
    "    'Yoruba'\n",
    "]\n",
    "base_dir = \"data/audios\"\n",
    "\n",
    "for language in tqdm(LANGUAGES, desc=\"Uploading languages\"):\n",
    "    print(f\"\\n--- Processing '{language}' ---\")\n",
    "    try:\n",
    "        alignment_df = get_alignment_dataframe(language, base_dir)\n",
    "\n",
    "        # Simple outlier removal, need to do better\n",
    "        alignment_df = alignment_df[alignment_df[\"duration_seconds\"] < 60]\n",
    "\n",
    "        repo_id = \"davidguzmanr/bible-tts-resources\"  # Change this to your repo ID\n",
    "\n",
    "        upload_alignment_to_hf(\n",
    "            alignment_df=alignment_df.head(100),\n",
    "            language=language,\n",
    "            repo_id=repo_id,\n",
    "            private=False,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error uploading '{language}': {e}\")\n",
    "    else:\n",
    "        print(f\"✓ Finished uploading '{language}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc89082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [00:00<00:00, 237.88 examples/s] shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 13.68ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 80.0MB / 80.0MB, 44.5MB/s  \n",
      "New Data Upload: 100%|██████████| 80.0MB / 80.0MB, 44.5MB/s  \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:05<00:00,  5.02s/ shards]\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "The read operation timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpx/_transports/default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {socket\u001b[38;5;241m.\u001b[39mtimeout: ReadTimeout, \u001b[38;5;167;01mOSError\u001b[39;00m: ReadError}\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Upload the dataset to Hugging Face\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Make sure you're logged in: huggingface-cli login\u001b[39;00m\n\u001b[1;32m      4\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdavidguzmanr/bible-tts-resources\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change this to your repo ID\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mupload_alignment_to_hf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43malignment_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malignment_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"Yoruba\"\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m, in \u001b[0;36mupload_alignment_to_hf\u001b[0;34m(alignment_df, language, repo_id, private)\u001b[0m\n\u001b[1;32m     29\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mcast_column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m, Audio())\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Push to hub with language as the config/split name\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use language as the config name\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# HF requires a split name, but you can ignore it when loading\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ Uploaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/datasets/arrow_dataset.py:6049\u001b[0m, in \u001b[0;36mDataset.push_to_hub\u001b[0;34m(self, repo_id, config_name, set_default, split, data_dir, commit_message, commit_description, private, token, revision, create_pr, max_shard_size, num_shards, embed_external_files, num_proc)\u001b[0m\n\u001b[1;32m   6045\u001b[0m dataset_card_additions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m   6046\u001b[0m     CommitOperationAdd(path_in_repo\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mREPOCARD_FILENAME, path_or_fileobj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(dataset_card)\u001b[38;5;241m.\u001b[39mencode())\n\u001b[1;32m   6047\u001b[0m )\n\u001b[1;32m   6048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 6049\u001b[0m     commit_info \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_commit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6051\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_commit_additions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset_card_additions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdeletions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommit_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_pr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_pr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6057\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent_commit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent_commit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6058\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6059\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HfHubHTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   6060\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6061\u001b[0m         err\u001b[38;5;241m.\u001b[39m__context__\n\u001b[1;32m   6062\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err\u001b[38;5;241m.\u001b[39m__context__, HfHubHTTPError)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6065\u001b[0m         \u001b[38;5;66;03m# 412 is Precondition failed (parent_commit isn't satisfied)\u001b[39;00m\n\u001b[1;32m   6066\u001b[0m         \u001b[38;5;66;03m# 409 is Conflict (another commit is in progress)\u001b[39;00m\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:89\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         validate_repo_id(arg_value)\n\u001b[1;32m     87\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_legacy_arguments(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/huggingface_hub/hf_api.py:1751\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_as_future(fn, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;66;03m# Otherwise, call the function normally\u001b[39;00m\n\u001b[0;32m-> 1751\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/huggingface_hub/hf_api.py:4443\u001b[0m, in \u001b[0;36mHfApi.create_commit\u001b[0;34m(self, repo_id, operations, commit_message, commit_description, token, repo_type, revision, create_pr, num_threads, parent_commit, run_as_future)\u001b[0m\n\u001b[1;32m   4440\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_pr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;28;01mif\u001b[39;00m create_pr \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4442\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4443\u001b[0m     commit_resp \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4444\u001b[0m     hf_raise_for_status(commit_resp, endpoint_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpx/_client.py:1144\u001b[0m, in \u001b[0;36mClient.post\u001b[0;34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1125\u001b[0m     url: URL \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     extensions: RequestExtensions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1138\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;124;03m    Send a `POST` request.\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \n\u001b[1;32m   1142\u001b[0m \u001b[38;5;124;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpx/_client.py:825\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    810\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    813\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    814\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    824\u001b[0m )\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpx/_transports/default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhttpcore\u001b[39;00m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/scratch/.conda/envs/ReadAlongs/lib/python3.10/site-packages/httpx/_transports/default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: The read operation timed out"
     ]
    }
   ],
   "source": [
    "# Upload the dataset to Hugging Face\n",
    "# Make sure you're logged in: huggingface-cli login\n",
    "\n",
    "repo_id = \"davidguzmanr/bible-tts-resources\"  # Change this to your repo ID\n",
    "\n",
    "upload_alignment_to_hf(\n",
    "    alignment_df=alignment_df.head(100),\n",
    "    language=language,  # \"Yoruba\"\n",
    "    repo_id=repo_id,\n",
    "    private=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f09438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the dataset later, use:\n",
    "# from datasets import load_dataset\n",
    "# ds = load_dataset(\"YOUR_USERNAME/bible-tts\", \"Yoruba\")  # Load specific language\n",
    "# ds = load_dataset(\"YOUR_USERNAME/bible-tts\", \"Hausa\")   # Load another language"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReadAlongs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
